{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------LIBRERIAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\"graficas\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "\"\"\"preprocesar\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "\"\"\"dividir datos\"\"\"\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\"\"\"validar modelo\"\"\"\n",
    "from sklearn.model_selection import validation_curve, StratifiedKFold, GridSearchCV, cross_validate\n",
    "\"\"\"metricas de evaluacion\"\"\"\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, make_scorer\n",
    "\"\"\"modelos ML\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#----------------------------------------FUNCIONES\n",
    "\"\"\" crear Funcion para matriz de confusion \"\"\"\n",
    "def crearMatriz_confusion(y_pred,y_test):\n",
    "    cm= confusion_matrix(y_pred, y_test)\n",
    "    plt.figure(figsize = (8,6))\n",
    "    values = [\"{0:0.0f}\".format(x) for x in cm.flatten()]\n",
    "    \"\"\" calcular y obtener valores\"\"\"\n",
    "    percentages = [\"{0:.2%}\".format(x) for x in cm.flatten()/np.sum(cm)]\n",
    "    combined = [\"{}\\n{}\\n\".format(j, k) for j, k in zip(values, percentages)]\n",
    "    combined = np.asarray(combined).reshape(4,4)\n",
    "    \"\"\"crear matriz\"\"\"\n",
    "    b = sns.heatmap(cm, annot=combined, fmt=\"\")\n",
    "    \"\"\"etiquetas\"\"\"\n",
    "    b.set(title='Confusion Matrix')\n",
    "    b.set(xlabel='Prediccion', ylabel='Actual',)\n",
    "    #plt.savefig('matrizconfusionDT_final.png')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"crear funcion para encontrar metricas del modelo \"\"\"\n",
    "def encontrar_metricas(y_test,y_pred):\n",
    "    \"\"\" encontrar la precision del general del modelo\"\"\"\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    precision_ma = precision_score(y_test, y_pred, average='weighted')*100\n",
    "    recall_ma = recall_score(y_test, y_pred, average='weighted')*100\n",
    "    f1score_ma = f1_score(y_test, y_pred, average='weighted')*100\n",
    "    return print('Accuracy: %s \\nPrecision: %s \\nRecall: %s \\nF1-Score: %s' %(accuracy, precision_ma, recall_ma, f1score_ma))\n",
    "\n",
    "\n",
    "#---------------------------------------- SELECCION DE DATOS\n",
    "df_traffic = pd.read_csv('../../../araData/Z/balance_total4clases_34200.csv', low_memory=False)\n",
    "\"\"\"matriz de caracteristicas\"\"\"\n",
    "caracteristicas = ['Dur','protoTcp','protoUdp','portSystem','portUser','portDynamic','TotPkts', 'SrcPkts', 'DstPkts', \n",
    "                    'TotBytes', 'SrcBytes', 'DstBytes']\n",
    "print(\"############# 1. Caracteristicas: %s ###############\" %len(caracteristicas) )\n",
    "\n",
    "\"\"\"seleccion de variables\"\"\"\n",
    "X= df_traffic[caracteristicas].values\n",
    "y=df_traffic.iloc[:,-1].values\n",
    "\n",
    "print(\"############# 2. Division de datos #############\")\n",
    "\"\"\"division de datos\"\"\"\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=1)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index,\"\\n\")\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1 )\n",
    "\"\"\"estandarizar datos\"\"\"\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)\n",
    "\n",
    "\n",
    "#----------------------------------------MODELO\n",
    "print(\"############ 3. Seleccionando modelo #############\")\n",
    "\n",
    "\"\"\"validacion cruzada\"\"\"\n",
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "print(\"############ 4. Entrenando modelo #############\")\n",
    "svm_clf = SVC(kernel = \"sigmoid\", random_state = 0)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"############ 4. Evaluando modelo #############\")\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "#----------------------------------------METRICAS Y EVALUACION\n",
    "print(\"############ 5. Metricas del modelo #############\")\n",
    "\"\"\" metricas\"\"\"\n",
    "encontrar_metricas(y_test,y_pred)\n",
    "crearMatriz_confusion(y_pred,y_test)\n",
    "print(classification_report(y_pred,y_test))#ver nro de instancias por clase\n",
    "\n",
    "print('################## 6. Validar resultados de Modelo ####################')\n",
    "score = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average='weighted'),\n",
    "         'recall': make_scorer(recall_score, average='weighted'),'f1_score': make_scorer(f1_score, average= 'weighted')}\n",
    "\n",
    "eval_resultado = cross_validate(estimator=svm_clf, X=X_train, y=y_train, cv=skf, scoring=score)\n",
    "print('Accuracy: ',  (np.mean(eval_resultado['test_accuracy'])*100))\n",
    "print('Precision: ', (np.mean(eval_resultado['test_precision'])*100))\n",
    "print('Recall: ', (np.mean(eval_resultado['test_recall'])*100))\n",
    "print('F1-Score: ', (np.mean(eval_resultado['test_f1_score'])*100))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
