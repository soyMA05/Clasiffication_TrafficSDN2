{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# 1. Caracteristicas: 15 ###############\n",
      "############# 2. Division de datos #############\n",
      "############ 3. Seleccionando modelo #############\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\"graficas\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "\"\"\"preprocesar\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "\"\"\"dividir datos\"\"\"\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\"\"\"validar modelo\"\"\"\n",
    "from sklearn.model_selection import validation_curve, StratifiedKFold, GridSearchCV, cross_validate\n",
    "\"\"\"metricas de evaluacion\"\"\"\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, make_scorer\n",
    "\"\"\"modelos ML\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "\"\"\" crear Funcion para matriz de confusion \"\"\"\n",
    "def crearMatriz_confusion(y_pred,y_test):\n",
    "    cm= confusion_matrix(y_pred, y_test)\n",
    "    plt.figure(figsize = (8,6))\n",
    "\n",
    "    values = [\"{0:0.0f}\".format(x) for x in cm.flatten()]\n",
    "\n",
    "    \"\"\" calcular y obtener valores\"\"\"\n",
    "    percentages = [\"{0:.2%}\".format(x) for x in cm.flatten()/np.sum(cm)]\n",
    "    combined = [\"{}\\n{}\\n\".format(j, k) for j, k in zip(values, percentages)]\n",
    "    combined = np.asarray(combined).reshape(5,5)\n",
    "    \"\"\"crear matriz\"\"\"\n",
    "    b = sns.heatmap(cm, annot=combined, fmt=\"\")\n",
    "    b.set_xticklabels(['DDoS(0)','Dos(1)','Normal(2)','Probe(3)', 'Botnet(4)'],fontsize=10)\n",
    "    b.set_yticklabels(['DDoS(0)','Dos(1)','Normal(2)','Probe(3)', 'Botnet(4)'],fontsize=10)\n",
    "    \"\"\"etiquetas\"\"\"\n",
    "    b.set(title='Confusion Matrix')\n",
    "    b.set(xlabel='Prediccion', ylabel='Actual',)\n",
    "    plt.savefig('matrizconfusionRF_featuresG2.png')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"crear funcion para encontrar metricas del modelo \"\"\"\n",
    "def encontrar_metricas(y_test,y_pred):\n",
    "    \"\"\" encontrar la precision del general del modelo\"\"\"\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    precision_ma = precision_score(y_test, y_pred, average='weighted')*100\n",
    "    recall_ma = recall_score(y_test, y_pred, average='weighted')*100\n",
    "    f1score_ma = f1_score(y_test, y_pred, average='weighted')*100\n",
    "    return print('Accuracy: %s \\nPrecision: %s \\nRecall: %s \\nF1-Score: %s' %(accuracy, precision_ma, recall_ma, f1score_ma))\n",
    "\n",
    "\n",
    "df_traffic = pd.read_csv('../balance_Tot5Clases_34200.csv', low_memory=False)\n",
    "\"\"\"matriz de caracteristicas\"\"\"\n",
    "caracteristicas = ['Dur','protoTcp','protoUdp','portSystem','portUser','portDynamic','TotPkts', 'SrcPkts', 'DstPkts', \n",
    "                    'TotBytes', 'SrcBytes', 'DstBytes', 'Rate', 'SrcRate', 'DstRate']\n",
    "print(\"############# 1. Caracteristicas: %s ###############\" %len(caracteristicas) )\n",
    "\n",
    "\"\"\"seleccion de variables\"\"\"\n",
    "X= df_traffic[caracteristicas].values\n",
    "y=df_traffic.iloc[:,-1].values\n",
    "\n",
    "print(\"############# 2. Division de datos #############\")\n",
    "\"\"\"division de datos\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=9 )\n",
    "\n",
    "\"\"\"estandarizar datos\"\"\"\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"############ 3. Seleccionando modelo #############\")\n",
    "inicio_hp = time.time()\n",
    "\"\"\"validacion cruzada\"\"\"\n",
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "parametros_grid = [{'n_estimators': [5, 8, 10], 'criterion' :['gini', 'entropy','log_loss'],\n",
    "                    'max_depth' : [3, 5, 8, 10, 12],\n",
    "                    \"min_samples_split\": [2, 5, 7, 10],\n",
    "                    \"min_samples_leaf\": [1, 2, 3, 4, 5, 9],\n",
    "                    'ccp_alpha':[0.0001, 0.0002, 0.0003, 0.001, 0.01,0.5],\n",
    "                }]\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "grid_search= GridSearchCV(estimator = rf, param_grid = parametros_grid, cv = skf, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Mejores hiperparametros: \", grid_search.best_params_)\n",
    "print(\"Mejor puntuacion: \", grid_search.best_score_)\n",
    "print(\"Modelo: \", grid_search.best_estimator_)\n",
    "print(\"Tiempo de Hiperparametros:\" + time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - inicio_hp)))\n",
    "\n",
    "print(\"############ 4. Entrenando modelo #############\")\n",
    "clf_rf = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'],\n",
    "                                criterion = grid_search.best_params_['criterion'],\n",
    "                                max_depth = grid_search.best_params_['max_depth'],\n",
    "                                min_samples_split = grid_search.best_params_['min_samples_split'],\n",
    "                                min_samples_leaf = grid_search.best_params_['min_samples_leaf'],\n",
    "                                ccp_alpha = grid_search.best_params_['ccp_alpha'],\n",
    "                               random_state=1)\n",
    "clf_rf = clf_rf.fit(X_train,y_train)\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"############ 5. Metricas del modelo #############\")\n",
    "\"\"\" metricas\"\"\"\n",
    "encontrar_metricas(y_test,y_pred)\n",
    "print(classification_report(y_pred,y_test))#ver nro de instancias por clase\n",
    "crearMatriz_confusion(y_pred,y_test)\n",
    "\n",
    "print('################## 6. Validar resultados de Modelo ####################')\n",
    "score = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average='weighted'),\n",
    "         'recall': make_scorer(recall_score, average='weighted'),'f1_score': make_scorer(f1_score, average= 'weighted')}\n",
    "\n",
    "eval_resultado = cross_validate(estimator=clf_rf, X=X_train, y=y_train, cv=skf, scoring=score)\n",
    "print('Accuracy: ',  (np.mean(eval_resultado['test_accuracy'])*100))\n",
    "print('Precision: ', (np.mean(eval_resultado['test_precision'])*100))\n",
    "print('Recall: ', (np.mean(eval_resultado['test_recall'])*100))\n",
    "print('F1-Score: ', (np.mean(eval_resultado['test_f1_score'])*100))\n",
    "\n",
    "\n",
    "\"\"\"Grafica de entrenamiento del modelo\"\"\"\n",
    "param_range = np.arange(1, (grid_search.best_params_['max_depth']+1),1)\n",
    "train_scores, test_scores = validation_curve(clf_rf, X_train, y_train, \n",
    "                            param_name=\"max_depth\", param_range=param_range, cv=skf,\n",
    "                                             scoring=\"accuracy\", n_jobs=-1)\n",
    "\"\"\"calcular el promedio y desviacion standar del entrenamiento \"\"\"\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "\"\"\"calcular el promedio y desviacion standar del conjunto de prueba \"\"\"\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\"\"\"mostrar valores obtenidos del conjunto de entrenamiento y prueba\"\"\"\n",
    "plt.plot(param_range, train_scores_mean - train_scores_std,\n",
    "     label = \"Training Score\", color = 'r')\n",
    "plt.plot(param_range, test_scores_mean - test_scores_std,\n",
    "   label = \"Cross Validation Score\", color = 'b')\n",
    " \n",
    "\"\"\"crear grafica\"\"\"\n",
    "plt.title(\"Validation Curve for Random Forest\")\n",
    "plt.xlabel(\"depth tree \")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = 'best')\n",
    "plt.savefig('RF_curve_featuresG2.png')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"CURVA ROC\"\"\"\n",
    "y_lbtest = label_binarize(y_test,classes=[0, 1, 2, 3, 4])\n",
    "y_lbpred = label_binarize(y_pred,classes=[0, 1, 2, 3, 4])\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thresh=dict()\n",
    "roc_auc = dict()\n",
    "for i in range(5):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_lbtest[:,i], y_lbpred[:,i] )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors = cycle(['purple', 'darkorange','blue','lime', 'red'])\n",
    "clases = ['DDos','DoS', 'Normal', 'Probe', 'Botnet']\n",
    "for i, color, clase in zip(range(5), colors, clases):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='{0} (AUC = {1:0.4f})'\n",
    "             ''.format(clase, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (Sensitivity)')\n",
    "plt.ylabel('True Positive Rate (1-Specificity)')\n",
    "plt.title('Curve ROC Random Forest ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('RF_roc_featuresG2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
