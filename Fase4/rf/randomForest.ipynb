{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\"graficas\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "\"\"\"preprocesar\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "\"\"\"dividir datos\"\"\"\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\"\"\"validar modelo\"\"\"\n",
    "from sklearn.model_selection import validation_curve, StratifiedKFold, GridSearchCV, cross_validate\n",
    "\"\"\"metricas de evaluacion\"\"\"\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, make_scorer\n",
    "\"\"\"modelos ML\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\"\"\" crear Funcion para matriz de confusion \"\"\"\n",
    "def crearMatriz_confusion(y_pred,y_test):\n",
    "    cm= confusion_matrix(y_pred, y_test)\n",
    "    plt.figure(figsize = (8,6))\n",
    "\n",
    "    values = [\"{0:0.0f}\".format(x) for x in cm.flatten()]\n",
    "\n",
    "    \"\"\" calcular y obtener valores\"\"\"\n",
    "    percentages = [\"{0:.2%}\".format(x) for x in cm.flatten()/np.sum(cm)]\n",
    "    combined = [\"{}\\n{}\\n\".format(j, k) for j, k in zip(values, percentages)]\n",
    "    combined = np.asarray(combined).reshape(4,4)\n",
    "\n",
    "    \"\"\"crear matriz\"\"\"\n",
    "    b = sns.heatmap(cm, annot=combined, fmt=\"\")\n",
    "    b.set_xticklabels(['DDoS(0)','Dos(1)','Normal(2)','Probe(3)'],fontsize=10)\n",
    "    b.set_yticklabels(['DDoS(0)','Dos(1)','Normal(2)','Probe(3)'],fontsize=10)\n",
    "    \"\"\"etiquetas\"\"\"\n",
    "    b.set(title='Confusion Matrix')\n",
    "    b.set(xlabel='Prediccion', ylabel='Actual',)\n",
    "    #plt.savefig('matrizconfusion_mobiln.png')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"crear funcion para encontrar metricas del modelo \"\"\"\n",
    "def encontrar_metricas(y_test,y_pred):\n",
    "    \"\"\" encontrar la precision del general del modelo\"\"\"\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    precision_ma = precision_score(y_test, y_pred, average='weighted')*100\n",
    "    recall_ma = recall_score(y_test, y_pred, average='weighted')*100\n",
    "    f1score_ma = f1_score(y_test, y_pred, average='weighted')*100\n",
    "    return print('Accuracy: %s \\nPrecision: %s \\nRecall: %s \\nF1-Score: %s' %(accuracy, precision_ma, recall_ma, f1score_ma))\n",
    "\n",
    "\n",
    "df_traffic = pd.read_csv('../3_Scaling/DB_34/balance_total4clases_34200.csv', low_memory=False)\n",
    "\"\"\"matriz de caracteristicas\"\"\"\n",
    "caracteristicas = ['Dur','protoTcp','protoUdp','portSystem','portUser','portDynamic','TotPkts', 'SrcPkts', 'DstPkts', \n",
    "                    'TotBytes', 'SrcBytes', 'DstBytes']\n",
    "print(\"############# 1. Caracteristicas: %s ###############\" %len(caracteristicas) )\n",
    "\n",
    "\"\"\"seleccion de variables\"\"\"\n",
    "X= df_traffic[caracteristicas].values\n",
    "y=df_traffic.iloc[:,-1].values\n",
    "\n",
    "print(\"############# 2. Division de datos #############\")\n",
    "\"\"\"division de datos\"\"\"\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=1)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index,\"\\n\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\"\"\"estandarizar datos\"\"\"\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)\n",
    "\n",
    "\"\"\"validacion cruzada\"\"\"\n",
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "print(\"############ 3. Seleccionando modelo #############\")\n",
    "parametros_grid = [{'n_estimators': [100, 200, 300, 400, 500, 1000], 'criterion' :['gini', 'entropy','log_loss'],\n",
    "                    'max_depth' : [5, 6, 7, 8, 9, 10, 20, 30],\n",
    "                    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                    'bootstrap': [True, False],\n",
    "                    'class_weight':['balanced', 'balanced_subsample'],\n",
    "                    'ccp_alpha':[0.001, 0.01,0.5, 1, 5, 10],\n",
    "                }]\n",
    "\n",
    "rf = RandomForestClassifier(metric = \"minkowski\",  p = 2)\n",
    "grid_search= GridSearchCV(estimator = rf, param_grid = parametros_grid, cv = skf, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Mejores hiperparametros: \", grid_search.best_params_)\n",
    "print(\"Mejor puntuacion: \", grid_search.best_score_)\n",
    "print(\"Modelo: \", grid_search.best_estimator_)\n",
    "\n",
    "print(\"############ 4. Entrenando modelo #############\")\n",
    "clf_rf = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'],\n",
    "                                criterion = grid_search.best_params_['criterion'],\n",
    "                                max_depth = grid_search.best_params_['max_depth'],\n",
    "                                max_features = grid_search.best_params_['max_features'],\n",
    "                                bootstrap = grid_search.best_params_['bootstrap'],\n",
    "                                class_weight = grid_search.best_params_['class_weight'],\n",
    "                                ccp_alpha = grid_search.best_params_['ccp_alpha'])\n",
    "clf_rf = clf_rf.fit(X_train,y_train)\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"############ 5. Metricas del modelo #############\")\n",
    "\"\"\" metricas\"\"\"\n",
    "encontrar_metricas(y_test,y_pred)\n",
    "print(classification_report(y_pred,y_test))#ver nro de instancias por clase\n",
    "crearMatriz_confusion(y_pred,y_test)\n",
    "\n",
    "print('################## 6. Validar resultados de Modelo ####################')\n",
    "score = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average='weighted'),\n",
    "         'recall': make_scorer(recall_score, average='weighted'),'f1_score': make_scorer(f1_score, average= 'weighted')}\n",
    "\n",
    "eval_resultado = cross_validate(estimator=clf_rf, X=X_train, y=y_train, cv=skf, scoring=score)\n",
    "print('Accuracy: ',  (np.mean(eval_resultado['test_accuracy'])*100))\n",
    "print('Precision: ', (np.mean(eval_resultado['test_precision'])*100))\n",
    "print('Recall: ', (np.mean(eval_resultado['test_recall'])*100))\n",
    "print('F1-Score: ', (np.mean(eval_resultado['test_f1_score'])*100))\n",
    "\n",
    "\n",
    "\"\"\"Grafica de entrenamiento del modelo\"\"\"\n",
    "param_range = np.arange(1, (grid_search.best_params_['max_depth']+1),1)\n",
    "train_scores, test_scores = validation_curve(clf_rf, X_train, y_train, \n",
    "                            param_name=\"max_depth\", param_range=param_range,\n",
    "                                             scoring=\"accuracy\", n_jobs=-1)\n",
    "\"\"\"calcular el promedio y desviacion standar del entrenamiento \"\"\"\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "\"\"\"calcular el promedio y desviacion standar del conjunto de prueba \"\"\"\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\"\"\"mostrar valores obtenidos del conjunto de entrenamiento y prueba\"\"\"\n",
    "plt.plot(param_range, train_scores_mean - train_scores_std,\n",
    "     label = \"Training Score\", color = 'r')\n",
    "plt.plot(param_range, test_scores_mean - test_scores_std,\n",
    "   label = \"Cross Validation Score\", color = 'b')\n",
    " \n",
    "\"\"\"crear grafica\"\"\"\n",
    "plt.title(\"Validation Curve for KNN\")\n",
    "plt.xlabel(\"n_neighbors \")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = 'best')\n",
    "#plt.savefig('knn_validationcurve.png')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"CURVA ROC\"\"\"\n",
    "y_lbtest = label_binarize(y_test,classes=[0, 1, 2, 3])\n",
    "y_lbpred = label_binarize(y_pred,classes=[0, 1, 2, 3])\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thresh=dict()\n",
    "roc_auc = dict()\n",
    "for i in range(4):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_lbtest[:,i], y_lbpred[:,i] )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors = cycle(['red', 'darkorange', 'blue','lime'])\n",
    "clases = ['Normal','Dos','DDoS', 'Probe']\n",
    "for i, color, clase in zip(range(4), colors, clases):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='{0} (AUC = {1:0.4f})'\n",
    "             ''.format(clase, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curve ROC KNN Model ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('knn_curveroc.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c3d121086e35f129a20ca7f553230286826dfcc08161000ccf738c6df1a7518"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
